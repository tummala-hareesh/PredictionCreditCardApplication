{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for prediction outcome on credit card applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to create a supervised machine learning model to predict the outcome of a credit card application given a set of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Method of dropping rows with missing values\n",
    "We reload the original credit card dataset and clean the missing data by simply dropping the concerning rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefaulter</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>Approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender    Age   Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
       "0      b  30.83  0.000       u            g              w         v   \n",
       "1      a  58.67  4.460       u            g              q         h   \n",
       "2      a  24.50  0.500       u            g              q         h   \n",
       "3      b  27.83  1.540       u            g              w         v   \n",
       "4      b  20.17  5.625       u            g              w         v   \n",
       "\n",
       "   YearsEmployed PriorDefaulter Employed  CreditScore DriversLicense Citizen  \\\n",
       "0           1.25              t        t            1              f       g   \n",
       "1           3.04              t        t            6              f       g   \n",
       "2           1.50              t        f            0              f       g   \n",
       "3           3.75              t        t            5              t       g   \n",
       "4           1.71              t        f            0              f       s   \n",
       "\n",
       "  ZipCode  Income Approved  \n",
       "0   00202       0        +  \n",
       "1   00043     560        +  \n",
       "2   00280     824        +  \n",
       "3   00100       3        +  \n",
       "4   00120       0        +  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_original = pd.read_csv('../datasets/crx.data_named.csv', index_col=[0])\n",
    "cc_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefaulter</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>Approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>b</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>468</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>137</td>\n",
       "      <td>399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>361</td>\n",
       "      <td>395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "      <td>625</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.758725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1017.385507</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.978163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5210.102598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.207500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>395.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender  Age        Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
       "count     690  690  690.000000     690          690            690       690   \n",
       "unique      3  350         NaN       4            4             15        10   \n",
       "top         b    ?         NaN       u            g              c         v   \n",
       "freq      468   12         NaN     519          519            137       399   \n",
       "mean      NaN  NaN    4.758725     NaN          NaN            NaN       NaN   \n",
       "std       NaN  NaN    4.978163     NaN          NaN            NaN       NaN   \n",
       "min       NaN  NaN    0.000000     NaN          NaN            NaN       NaN   \n",
       "25%       NaN  NaN    1.000000     NaN          NaN            NaN       NaN   \n",
       "50%       NaN  NaN    2.750000     NaN          NaN            NaN       NaN   \n",
       "75%       NaN  NaN    7.207500     NaN          NaN            NaN       NaN   \n",
       "max       NaN  NaN   28.000000     NaN          NaN            NaN       NaN   \n",
       "\n",
       "        YearsEmployed PriorDefaulter Employed  CreditScore DriversLicense  \\\n",
       "count      690.000000            690      690    690.00000            690   \n",
       "unique            NaN              2        2          NaN              2   \n",
       "top               NaN              t        f          NaN              f   \n",
       "freq              NaN            361      395          NaN            374   \n",
       "mean         2.223406            NaN      NaN      2.40000            NaN   \n",
       "std          3.346513            NaN      NaN      4.86294            NaN   \n",
       "min          0.000000            NaN      NaN      0.00000            NaN   \n",
       "25%          0.165000            NaN      NaN      0.00000            NaN   \n",
       "50%          1.000000            NaN      NaN      0.00000            NaN   \n",
       "75%          2.625000            NaN      NaN      3.00000            NaN   \n",
       "max         28.500000            NaN      NaN     67.00000            NaN   \n",
       "\n",
       "       Citizen ZipCode         Income Approved  \n",
       "count      690     690     690.000000      690  \n",
       "unique       3     171            NaN        2  \n",
       "top          g   00000            NaN        -  \n",
       "freq       625     132            NaN      383  \n",
       "mean       NaN     NaN    1017.385507      NaN  \n",
       "std        NaN     NaN    5210.102598      NaN  \n",
       "min        NaN     NaN       0.000000      NaN  \n",
       "25%        NaN     NaN       0.000000      NaN  \n",
       "50%        NaN     NaN       5.000000      NaN  \n",
       "75%        NaN     NaN     395.500000      NaN  \n",
       "max        NaN     NaN  100000.000000      NaN  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_original.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load helper functions from src/utils-*-*.py to run on jupyter-notebook\n",
    "%run ../src/utils-gather-assess.py\n",
    "%run ../src/utils-explore-clean.py\n",
    "%run ../src/utils-models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_drop = cc_original.copy()\n",
    "\n",
    "# Replace all ? with Nan values\n",
    "for icol in cc_drop.columns:\n",
    "    replace_feature_missingvalues(cc_drop, icol, '?', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Details of column: Age\n",
      "        - dtype(o): object\n",
      "        - dtype(n): float64\n"
     ]
    }
   ],
   "source": [
    "# Drop all rows that are Nan\n",
    "cc_drop.dropna(inplace=True)\n",
    "\n",
    "# change datatype of Age feature\n",
    "change_feature_datatype(cc_drop, 'Age', float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 653 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Gender          653 non-null    object \n",
      " 1   Age             653 non-null    float64\n",
      " 2   Debt            653 non-null    float64\n",
      " 3   Married         653 non-null    object \n",
      " 4   BankCustomer    653 non-null    object \n",
      " 5   EducationLevel  653 non-null    object \n",
      " 6   Ethnicity       653 non-null    object \n",
      " 7   YearsEmployed   653 non-null    float64\n",
      " 8   PriorDefaulter  653 non-null    object \n",
      " 9   Employed        653 non-null    object \n",
      " 10  CreditScore     653 non-null    int64  \n",
      " 11  DriversLicense  653 non-null    object \n",
      " 12  Citizen         653 non-null    object \n",
      " 13  ZipCode         653 non-null    object \n",
      " 14  Income          653 non-null    int64  \n",
      " 15  Approved        653 non-null    object \n",
      "dtypes: float64(3), int64(2), object(11)\n",
      "memory usage: 86.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cc_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping rows with missing values, we end up with 653 rows/instances for 15 features and 1 target variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_drop.to_csv('../datasets/crx.data_drop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " datasets/\n",
      "       - crx.data\n",
      "       - crx.names\n",
      "       - crx.data_named.csv\n",
      "       - crx.data_drop.csv\n",
      "       - crx.data_clean.csv\n"
     ]
    }
   ],
   "source": [
    "show_files_datasets('../datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit card data is now loaded into a `cc_drop` dataframe. We now split the combined dataframe into `features` and `target` dataframe by performing **one_hot_encoding** on categorical variables in `features` dataframe.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naneen/.local/lib/python3.8/site-packages/pandas/core/frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into num_df, cat_df and target_df\n",
    "cc_drop_num, cc_drop_cat, cc_drop_target = split_dataframe_datatypes(cc_drop, 'Approved')\n",
    "cc_drop_features_combined = pd.concat([cc_drop_num, cc_drop_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "   Gender Married BankCustomer EducationLevel Ethnicity PriorDefaulter  \\\n",
      "0      b       u            g              w         v              t   \n",
      "1      a       u            g              q         h              t   \n",
      "2      a       u            g              q         h              t   \n",
      "3      b       u            g              w         v              t   \n",
      "4      b       u            g              w         v              t   \n",
      "\n",
      "  Employed DriversLicense Citizen ZipCode  \n",
      "0        t              f       g   00202  \n",
      "1        t              f       g   00043  \n",
      "2        f              f       g   00280  \n",
      "3        t              t       g   00100  \n",
      "4        f              f       s   00120  \n",
      "\n",
      "After:\n",
      " (653, 10) [[ 1.  1.  0. ...  0.  0. 68.]\n",
      " [ 0.  1.  0. ...  0.  0. 11.]\n",
      " [ 0.  1.  0. ...  0.  0. 94.]\n",
      " ...\n",
      " [ 0.  2.  2. ...  1.  0. 67.]\n",
      " [ 1.  1.  0. ...  0.  0. 94.]\n",
      " [ 1.  1.  0. ...  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Perform Ordinal Encoding on Categorical features\n",
    "print('Before:\\n',cc_drop_cat.head())\n",
    "cc_drop_cat_nparray = apply_encoder_ordinal(cc_drop_cat)\n",
    "#cc_drop_cat_nparray = apply_encoder_one_hot(cc_drop_cat)\n",
    "print('\\nAfter:\\n',cc_drop_cat_nparray.shape, cc_drop_cat_nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "      Age   Debt  YearsEmployed  CreditScore  Income\n",
      "0  30.83  0.000           1.25            1       0\n",
      "1  58.67  4.460           3.04            6     560\n",
      "2  24.50  0.500           1.50            0     824\n",
      "3  27.83  1.540           3.75            5       3\n",
      "4  20.17  5.625           1.71            0       0\n",
      "\n",
      "After:\n",
      " (653, 5) [[3.083e+01 0.000e+00 1.250e+00 1.000e+00 0.000e+00]\n",
      " [5.867e+01 4.460e+00 3.040e+00 6.000e+00 5.600e+02]\n",
      " [2.450e+01 5.000e-01 1.500e+00 0.000e+00 8.240e+02]\n",
      " ...\n",
      " [2.525e+01 1.350e+01 2.000e+00 1.000e+00 1.000e+00]\n",
      " [1.792e+01 2.050e-01 4.000e-02 0.000e+00 7.500e+02]\n",
      " [3.500e+01 3.375e+00 8.290e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Convert df into numpy array --> Numerical variables\n",
    "print('Before:\\n',cc_drop_num.head())\n",
    "cc_drop_num_nparray = cc_drop_num.to_numpy()\n",
    "print('\\nAfter:\\n',cc_drop_num_nparray.shape, cc_drop_num_nparray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we (atleast me!) forgets about the categorical target variable. This may result in model giving Nan results on the metrics you are tracking. Let's not do that this time around! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      " 0      +\n",
      "1      +\n",
      "2      +\n",
      "3      +\n",
      "4      +\n",
      "      ..\n",
      "685    -\n",
      "686    -\n",
      "687    -\n",
      "688    -\n",
      "689    -\n",
      "Name: Approved, Length: 653, dtype: object\n",
      "\n",
      "After:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Perform Label Encoding on Categorical target variable\n",
    "print('Before:\\n', cc_drop_target['Approved'])\n",
    "cc_drop_target_nparray = apply_encoder_label(cc_drop_target['Approved'])\n",
    "print('\\nAfter:\\n',cc_drop_target_nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 15)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined features np.array\n",
    "cc_drop_combined_nparray = combine_two_nparrays(cc_drop_cat_nparray, cc_drop_num_nparray)\n",
    "cc_drop_combined_nparray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cc_drop_combined_scaled = apply_standard_scaling(cc_drop_combined_nparray)\n",
    "cc_drop_combined_scaled = cc_drop_combined_nparray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sneak into the shapes of dataframes that are now ready to go into supervised ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 15)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check size of features npa\n",
    "cc_drop_combined_nparray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check size of target npa\n",
    "cc_drop_target_nparray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into training and testing datasets\n",
    "ftrain, ftest, ttrain, ttest = get_train_test_dfs(cc_drop_combined_scaled, cc_drop_target_nparray, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train datatset: \n",
      " Shape of features: (457, 15) ==> Shape of target: (457,)\n",
      "\n",
      " Test_ datatset: \n",
      " Shape of features: (196, 15) ==> Shape of target: (196,)\n"
     ]
    }
   ],
   "source": [
    "# Looking at shapes of training and testing datasets\n",
    "print(' Train datatset: \\n Shape of features:',ftrain.shape, '==> Shape of target:',ttrain.shape)\n",
    "\n",
    "print('\\n Test_ datatset: \\n Shape of features:',ftest.shape, '==> Shape of target:',ttest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting to build a ML model, we first initialize model list and dicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the no. of processor \n",
    "nproc = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " List of models for cross-validation:\n",
      "\n",
      " 0 LogisticRegression()\n",
      " 1 SVC()\n",
      " 2 RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "# initialize models list\n",
    "models = []\n",
    "\n",
    "# get basic classification models\n",
    "model_set1 = get_classifiers_basic('all', False)\n",
    "#model_set2 = get_classifiers_basic('all', True)\n",
    "\n",
    "# Update models list\n",
    "models.extend(model_set1)\n",
    "#models.extend(model_set2)\n",
    "\n",
    "# List of models to perform cross-validation on.\n",
    "print(' List of models for cross-validation:\\n')\n",
    "for imodel, model in enumerate(models):\n",
    "    print(' {} {}'.format(imodel,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation to predict feature importance  \n",
    "models_scores = {}\n",
    "for model in models:\n",
    "    scores = train_model(model, ftrain, ttrain, nproc, 3, False)\n",
    "    models_scores[model] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_models_metrics_scores(models_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "| Model                | fit_time     | score_time   | test_accs    | test_f1_s    | test_rocs    |\n",
      "| -------------------- | ------------ | ------------ | ------------ | ------------ | ------------ |\n",
      "| LogisticRegression() |    0.0317022 |   0.00308164 |    0.8293487 |   0.84800212 |   0.89110637 |\n",
      "| SVC()                |   0.00489362 |    0.0065399 |    0.6585684 |   0.74696658 |   0.68442674 |\n",
      "| RandomForestClassifi |    0.2245117 |   0.03224134 |   0.87967263 |    0.8898694 |   0.93560751 |\n"
     ]
    }
   ],
   "source": [
    "# Print models-metrics-scores in a table\n",
    "pprint_models_metrics_scores(models_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great! We have now created a readable table for our model-metrics-scores.  This makes it so much easier to visually interpret the models, their metrics and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model with max.ACCURACY is: RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "# Get the best of models\n",
    "model = get_best_model(models_scores, 'test_accs')\n",
    "print ('\\n Best model with max.ACCURACY is:', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Get & Set hyper-parameter for convergence\n",
    "hparams = model.get_params()\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the best model with min.MSE for finalizing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0\n",
      "Test_ Score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# train the model on the dataset\n",
    "model.fit(ftrain, ttrain)\n",
    "prediction = model.predict(ftest)\n",
    "\n",
    "print('Train Score:', model.score(ftrain, ttrain))\n",
    "print('Test_ Score:',model.score(ftest, ttest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performs good with close to 83% accuracy. We now are going to create a pipeline to select standarized features  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-9ca91d713512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#store feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeature_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcc_drop_features_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'importance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeature_importances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "#store feature importances\n",
    "importances = np.absolute(model.coef_[0])\n",
    "\n",
    "feature_importances = pd.DataFrame({'feature':cc_drop_features_combined.columns, 'importance':importances})\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "#set index to 'feature'\n",
    "feature_importances.set_index('feature', inplace=True, drop=True)\n",
    "\n",
    "#create plot\n",
    "feature_importances[0:25].plot.bar(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
